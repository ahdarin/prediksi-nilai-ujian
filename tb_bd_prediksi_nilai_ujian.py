# -*- coding: utf-8 -*-
"""tb-bd_prediksi_nilai_ujian.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UyBd3hnQyadcVowLNXMcAx1nn4qI6eHL
"""

# ==========================================
# IMPOR LIBRARY
# ==========================================

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import numpy as np
from sklearn.model_selection import GridSearchCV
import warnings
import joblib

# ==========================================
# LOAD DATA
# ==========================================

# Load the dataset
df = pd.read_csv('Exam_Score_Prediction.csv')

# Display the first 5 rows
print("First 5 rows of the DataFrame:")
print(df.head())
print("\n")

# Print the shape of the DataFrame
print("Shape of the DataFrame (rows, columns):")
print(df.shape)
print("\n")

# Print a concise summary of the DataFrame
print("Concise summary of the DataFrame:")
df.info()
print("\n")

# Generate descriptive statistics for numerical columns
print("Descriptive statistics for numerical columns:")
print(df.describe())
print("\n")

# Check for missing values
print("Sum of missing values in each column:")
print(df.isnull().sum())

# ==========================================
# EDA (VISUALISASI)
# ==========================================

# Identify numerical and categorical columns
numerical_cols = ['age', 'study_hours', 'class_attendance', 'sleep_hours', 'exam_score']
categorical_cols = ['gender', 'course', 'internet_access', 'sleep_quality', 'study_method', 'facility_rating', 'exam_difficulty']

print("Generating Histograms for Numerical Columns...")
# Histograms for numerical columns
for col in numerical_cols:
    plt.figure(figsize=(8, 5))
    sns.histplot(df[col], kde=True)
    plt.title(f'Distribution of {col.replace("_", " ").title()}')
    plt.xlabel(col.replace("_", " ").title())
    plt.ylabel('Frequency')
    plt.show()
print("Histograms generated.\n")

print("Generating Count Plots for Categorical Columns...")
# Count plots for categorical columns
for col in categorical_cols:
    plt.figure(figsize=(10, 6))
    sns.countplot(data=df, x=col, order=df[col].value_counts().index)
    plt.title(f'Count Plot of {col.replace("_", " ").title()}')
    plt.xlabel(col.replace("_", " ").title())
    plt.ylabel('Count')
    plt.xticks(rotation=45, ha='right')
    plt.tight_layout()
    plt.show()
print("Count plots generated.\n")

print("Generating Pair Plot for Numerical Columns (this may take a moment)...")
# Pair plot for numerical columns
sns.pairplot(df[numerical_cols])
plt.suptitle('Pair Plot of Numerical Features', y=1.02) # Adjust suptitle to not overlap with axes
plt.show()
print("Pair plot generated.\n")

print("Generating Correlation Heatmap for Numerical Columns...")
# Correlation heatmap for numerical columns
plt.figure(figsize=(10, 8))
correlation_matrix = df[numerical_cols].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)
plt.title('Correlation Heatmap of Numerical Features')
plt.show()
print("Correlation heatmap generated.\n")

# ==========================================
# PREPROCESSING
# ==========================================

print("Starting data preprocessing setup...")

# Drop ID
df_processed = df.drop('student_id', axis=1)

# Define X (Fitur MENTAH) dan y (Target)
y = df_processed['exam_score']
X = df_processed.drop('exam_score', axis=1)
# CATATAN: X di sini masih berisi teks (Male, b.com, dll). Kita biarkan begitu.

# Define columns
ordinal_cols = ['sleep_quality', 'facility_rating', 'exam_difficulty']
onehot_cols = ['gender', 'course', 'internet_access', 'study_method']
numeric_cols_to_scale = ['study_hours', 'class_attendance', 'age']

# Define categories
sleep_quality_categories = ['poor', 'average', 'good']
facility_rating_categories = ['low', 'medium', 'high'] # Sesuaikan dengan data asli (low/moderate/high)
exam_difficulty_categories = ['easy', 'moderate', 'hard'] # Sesuaikan dengan data asli

categories_list = [
    sleep_quality_categories,
    facility_rating_categories,
    exam_difficulty_categories
]

# Create Preprocessor
preprocessor = ColumnTransformer(
    transformers=[
        ('ord', OrdinalEncoder(categories=categories_list), ordinal_cols),
        ('onehot', OneHotEncoder(handle_unknown='ignore'), onehot_cols),
        ('scaler', StandardScaler(), numeric_cols_to_scale)
    ],
    remainder='passthrough'
)

# <--- PERUBAHAN PENTING:
# Kita TIDAK melakukan fit_transform di sini secara manual ke variabel baru.
# Kita biarkan preprocessor ini masuk ke dalam Pipeline nanti.

print("Preprocessing setup complete.")

# ==========================================
# DATA SPLITTING
# ==========================================

print("Splitting data...")
# Kita split data yang masih MENTAH. Biarkan Pipeline yang mengurus transformasinya nanti.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

print(f"X_train shape: {X_train.shape} (Masih mengandung data teks)")
print(f"y_train shape: {y_train.shape}")

# ==========================================
# MODELING DENGAN PIPELINE (DIPERBAIKI)
# ==========================================

# <--- PERUBAHAN PENTING: Membuat Pipeline untuk setiap model
# Pipeline = Preprocessor + Model

# 1. Linear Regression Pipeline
pipeline_lr = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', LinearRegression())
])

# 2. Random Forest Pipeline
pipeline_rf = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', RandomForestRegressor(random_state=42, n_jobs=-1))
])

# 3. XGBoost Pipeline
pipeline_xgb = Pipeline([
    ('preprocessor', preprocessor),
    ('regressor', XGBRegressor(random_state=42, n_jobs=-1, tree_method='hist'))
])

models = {
    'Linear Regression': pipeline_lr,
    'Random Forest': pipeline_rf,
    'XGBoost': pipeline_xgb
}

print("\nTraining & Evaluating Pipelines...")
results = {}

for name, pipeline in models.items():
    print(f"\n--- Training {name} ---")

    # Fit Pipeline
    pipeline.fit(X_train, y_train)

    # Predict
    y_pred = pipeline.predict(X_test)

    # Metrics
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)

    results[name] = {'MAE': mae, 'RMSE': rmse, 'R2 Score': r2}

    # <--- BAGIAN INI YANG SAYA TAMBAHKAN AGAR MUNCUL:
    print(f'MAE: {mae:.4f}')
    print(f'RMSE: {rmse:.4f}')
    print(f'R2 Score: {r2:.4f}')

# --- TAMBAHAN: MENAMPILKAN TABEL PERBANDINGAN ---
print("\n\n--- Perbandingan Hasil Akhir ---")
df_results = pd.DataFrame(results).T
print(df_results)

# ==========================================
# HYPERPARAMETER TUNING
# ==========================================

warnings.filterwarnings('ignore')

print("\nStarting Hyperparameter Tuning...")

# <--- PERUBAHAN PENTING:
# Karena model ada di dalam pipeline dengan nama 'regressor',
# nama parameter harus diberi prefix 'regressor__'

# --- Random Forest Tuning ---
param_grid_rf = {
    'regressor__n_estimators': [100, 200],      # Tambah prefix regressor__
    'regressor__max_depth': [10, 20],           # Tambah prefix regressor__
    'regressor__min_samples_split': [2, 5]      # Tambah prefix regressor__
}

grid_search_rf = GridSearchCV(
    pipeline_rf,    # Masukkan PIPELINE, bukan model saja
    param_grid_rf,
    cv=3,
    scoring='r2',
    n_jobs=-1,
    verbose=1
)
grid_search_rf.fit(X_train, y_train)
print(f"Best RF R2: {grid_search_rf.best_score_:.4f}")


# --- XGBoost Tuning ---
param_grid_xgb = {
    'regressor__n_estimators': [100, 200],      # Tambah prefix regressor__
    'regressor__learning_rate': [0.05, 0.1],    # Tambah prefix regressor__
    'regressor__max_depth': [5, 10]             # Tambah prefix regressor__
}

grid_search_xgb = GridSearchCV(
    pipeline_xgb,   # Masukkan PIPELINE
    param_grid_xgb,
    cv=3,
    scoring='r2',
    n_jobs=-1,
    verbose=1
)
grid_search_xgb.fit(X_train, y_train)
print(f"Best XGB R2: {grid_search_xgb.best_score_:.4f}")

# ==========================================
# SAVING FINAL MODEL
# ==========================================

print("\n--- Saving Models ---")

# Simpan Model Linear Regression (Pipeline)
# Ini yang akan dipakai di app.py
joblib_file = 'Linear_Regression_(Default)_model.joblib'
joblib.dump(pipeline_lr, joblib_file)
print(f"Model Linear Regression berhasil disimpan sebagai: {joblib_file}")

print("\nSELESAI. Silakan download file .joblib dan upload ke folder Streamlit.")

import sklearn
print(sklearn.__version__)
# Contoh output: 1.5.2